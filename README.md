# Dagen Reels App

This repository contains a minimal full‑stack implementation for converting news articles into branded video reels for **Dagen**.  It is split into a **frontend** folder for the user interface and a **backend** folder for the API that performs article summarisation, generates audio, produces subtitles and assembles a vertical video.

## Structure

```
wagen_reels_repo/
├── frontend/
│   ├── index.html        # Web UI with an input form and download link
│   ├── style.css         # Tailwind‑based styling with Dagen colours
│   └── script.js         # JavaScript to call the backend API
├── backend/
│   ├── __init__.py       # Marks the folder as a package
│   ├── main.py           # FastAPI application exposing `/convert` endpoint
│   ├── dagen_video_reels.py # Article→video pipeline (copy of earlier script)
│   └── requirements.txt  # Dependencies needed to run the backend
└── render.yaml           # Example Render blueprint to deploy both services
```

### Frontend

Open `frontend/index.html` in a browser.  It presents a simple form where you can paste a Dagen article URL and click **“Lag video”**.  The page calls the backend `/convert` endpoint and, when the conversion is complete, displays a link to download the resulting MP4 and subtitle file.

### Backend

The FastAPI app in `backend/main.py` defines a `/convert` endpoint which accepts a `url` query parameter.  For demonstration purposes this endpoint currently fetches the article and splits it into scenes but does not yet call the heavy TTS/video generation pipeline.  The real logic resides in `dagen_video_reels.py`; you can replace the stub with calls to functions there (see `generate_reel` for a complete pipeline).

To run the backend locally:

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

Then open `http://127.0.0.1:8000/docs` for interactive API documentation.

### Deploying to Render

The included `render.yaml` file defines two services: a **web** service for the backend and a **static** site for the frontend.  To deploy to Render:

1. Push this repository to a public Git provider (GitHub, GitLab, etc.).
2. In the Render dashboard, create a new **Web Service** and select the `backend` directory.  Use the build and start commands from the blueprint:
   - **Build Command:** `pip install -r requirements.txt`
   - **Start Command:** `uvicorn main:app --host 0.0.0.0 --port 8000`
3. Create a new **Static Site** and select the `frontend` directory.  Leave the build command blank and set the publish directory to `.` (the current folder).
4. Add environment variables on the backend service for any API keys (e.g. TTS provider).  For now the demo uses silent audio.

Once deployed, update `frontend/script.js` to point to your backend’s URL (e.g. `https://your-backend-on-render.onrender.com/convert`).  The site will then call your API and serve completed reels.

## Credits

This repository and accompanying pipeline were generated by the OpenAI ChatGPT agent as part of an interactive session with the user.
